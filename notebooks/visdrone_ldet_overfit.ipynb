{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fa3fd-29d1-4f75-8e36-c7100b1959e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook for overfitting Lnorm on one image of UAVDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e5be9a-f8e2-421a-8f5f-45d06c3f6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e70a5d6-e731-405b-bfe5-fba0968f0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add parent directory, it should add parent of parent\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import Res18FPNCEASC  # Adjust as needed\n",
    "from utils.visdrone_dataloader import get_dataset\n",
    "from utils.losses import Lnorm, Lamm, DetectionLoss  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73024509-5640-4aae-b8c2-bb2292bb249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_shape(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.shape\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        return [safe_shape(e) for e in x]\n",
    "    return type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc98f2c-0835-41be-9bb1-5e57d9e5fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# get the setup \n",
    "mode = \"train\"  # Change to \"eval\" or \"test\" as needed\n",
    "\n",
    "config = {\n",
    "    \"root_dir\": \"/home/soroush1/scratch/eecs_project\",\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 4,\n",
    "    \"num_epochs\": 1,\n",
    "    \"lr\": 1e-1,\n",
    "    \"config_path\": \"../configs/resnet18_fpn_feature_extractor.py\",\n",
    "}\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868a5894-f75c-427d-b1d6-d10125bab770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Inspecting `targets` structure:\n",
      "--- Sample 0 ---\n",
      "Image ID:         tensor([939])\n",
      "Original Size:    tensor([ 765, 1360])\n",
      "Boxes shape:      torch.Size([51, 4])\n",
      "Labels shape:     torch.Size([51])\n",
      "Boxes:            tensor([[1.1300e+02, 5.1100e+02, 2.8100e+02, 6.5400e+02],\n",
      "        [4.0400e+02, 6.7100e+02, 5.8200e+02, 7.6500e+02],\n",
      "        [4.9900e+02, 4.7700e+02, 6.0700e+02, 5.5600e+02],\n",
      "        [6.1400e+02, 5.3100e+02, 7.4100e+02, 6.3100e+02],\n",
      "        [6.3400e+02, 4.4400e+02, 7.6000e+02, 5.3400e+02],\n",
      "        [6.2200e+02, 3.6700e+02, 6.4600e+02, 4.0100e+02],\n",
      "        [6.1900e+02, 3.9000e+02, 6.5000e+02, 4.1600e+02],\n",
      "        [5.3100e+02, 3.0400e+02, 6.1500e+02, 3.6300e+02],\n",
      "        [7.7300e+02, 3.3100e+02, 8.9900e+02, 4.5500e+02],\n",
      "        [8.9300e+02, 2.7100e+02, 9.7800e+02, 3.5300e+02],\n",
      "        [9.6100e+02, 2.4200e+02, 1.0160e+03, 2.8100e+02],\n",
      "        [9.3400e+02, 1.9900e+02, 9.8500e+02, 2.2600e+02],\n",
      "        [1.0070e+03, 2.0000e+02, 1.0530e+03, 2.4000e+02],\n",
      "        [1.0760e+03, 2.0400e+02, 1.1220e+03, 2.3900e+02],\n",
      "        [1.0550e+03, 1.6600e+02, 1.0850e+03, 1.9700e+02],\n",
      "        [1.1110e+03, 1.5500e+02, 1.1490e+03, 1.8400e+02],\n",
      "        [1.0750e+03, 1.5100e+02, 1.1050e+03, 1.7600e+02],\n",
      "        [1.1350e+03, 2.6000e+01, 1.1490e+03, 4.2000e+01],\n",
      "        [1.1090e+03, 2.0000e+01, 1.1200e+03, 2.8000e+01],\n",
      "        [1.1110e+03, 1.8000e+01, 1.1170e+03, 2.6000e+01],\n",
      "        [1.0980e+03, 1.2300e+02, 1.1280e+03, 1.4800e+02],\n",
      "        [1.1440e+03, 1.2600e+02, 1.1730e+03, 1.5300e+02],\n",
      "        [1.1610e+03, 1.0100e+02, 1.1890e+03, 1.2700e+02],\n",
      "        [1.1200e+03, 1.0600e+02, 1.1450e+03, 1.2700e+02],\n",
      "        [1.0760e+03, 1.0000e+02, 1.1030e+03, 1.1900e+02],\n",
      "        [1.0960e+03, 8.9000e+01, 1.1220e+03, 1.0500e+02],\n",
      "        [1.1140e+03, 7.3000e+01, 1.1350e+03, 9.1000e+01],\n",
      "        [1.1820e+03, 8.9000e+01, 1.2050e+03, 1.0700e+02],\n",
      "        [1.1330e+03, 9.6000e+01, 1.1550e+03, 1.1400e+02],\n",
      "        [1.1410e+03, 8.7000e+01, 1.1640e+03, 1.0200e+02],\n",
      "        [1.1630e+03, 7.7000e+01, 1.1850e+03, 9.1000e+01],\n",
      "        [1.1500e+03, 6.9000e+01, 1.1690e+03, 8.5000e+01],\n",
      "        [1.1690e+03, 6.4000e+01, 1.1860e+03, 7.7000e+01],\n",
      "        [1.2020e+03, 6.3000e+01, 1.2230e+03, 8.0000e+01],\n",
      "        [1.2190e+03, 5.1000e+01, 1.2350e+03, 6.5000e+01],\n",
      "        [1.2340e+03, 3.2000e+01, 1.2430e+03, 4.4000e+01],\n",
      "        [1.2440e+03, 2.8000e+01, 1.2560e+03, 3.8000e+01],\n",
      "        [1.1810e+03, 5.9000e+01, 1.1980e+03, 7.2000e+01],\n",
      "        [1.1490e+03, 5.2000e+01, 1.1680e+03, 6.6000e+01],\n",
      "        [1.1560e+03, 4.4000e+01, 1.1710e+03, 5.9000e+01],\n",
      "        [1.1790e+03, 4.7000e+01, 1.1950e+03, 6.3000e+01],\n",
      "        [1.1710e+03, 3.8000e+01, 1.1830e+03, 4.9000e+01],\n",
      "        [1.1820e+03, 3.1000e+01, 1.1950e+03, 4.2000e+01],\n",
      "        [1.1880e+03, 2.9000e+01, 1.2020e+03, 4.0000e+01],\n",
      "        [1.2000e+03, 4.7000e+01, 1.2160e+03, 6.3000e+01],\n",
      "        [1.1960e+03, 3.7000e+01, 1.2150e+03, 5.7000e+01],\n",
      "        [1.2100e+03, 3.5000e+01, 1.2210e+03, 4.8000e+01],\n",
      "        [1.2140e+03, 3.0000e+01, 1.2270e+03, 4.2000e+01],\n",
      "        [1.1660e+03, 4.0000e+00, 1.1760e+03, 1.2000e+01],\n",
      "        [1.1490e+03, 1.0000e+00, 1.1600e+03, 1.3000e+01],\n",
      "        [1.1290e+03, 3.0000e+00, 1.1400e+03, 1.1000e+01]])\n",
      "Labels:           tensor([ 5,  4,  4,  4,  4,  2,  3,  4,  6,  6,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "        10,  2,  4,  4,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  4,\n",
      "         4,  4,  4,  5,  5,  4,  4,  4,  5,  6,  4,  4,  4,  4,  4])\n",
      "Loss Det, iter 0: 6.25349760055542\n",
      "\tLoss Det, iter 0: 2.2101547718048096\n",
      "\tLoss Det, iter 0: 3.117853879928589\n",
      "\tLoss Det, iter 0: 0.9254891276359558\n",
      "Loss Det, iter 100: 1.7753632068634033\n",
      "\tLoss Det, iter 100: 0.0548369437456131\n",
      "\tLoss Det, iter 100: 0.9319461584091187\n",
      "\tLoss Det, iter 100: 0.7885801792144775\n",
      "Loss Det, iter 200: 1.6059515476226807\n",
      "\tLoss Det, iter 200: 0.03233207017183304\n",
      "\tLoss Det, iter 200: 0.7855883240699768\n",
      "\tLoss Det, iter 200: 0.7880311608314514\n",
      "Loss Det, iter 300: 1.566206455230713\n",
      "\tLoss Det, iter 300: 0.023617234081029892\n",
      "\tLoss Det, iter 300: 0.7455273866653442\n",
      "\tLoss Det, iter 300: 0.7970618605613708\n",
      "Loss Det, iter 400: 1.4659137725830078\n",
      "\tLoss Det, iter 400: 0.016332700848579407\n",
      "\tLoss Det, iter 400: 0.663427472114563\n",
      "\tLoss Det, iter 400: 0.7861535549163818\n",
      "Loss Det, iter 500: 1.4018688201904297\n",
      "\tLoss Det, iter 500: 0.009305555373430252\n",
      "\tLoss Det, iter 500: 0.6033652424812317\n",
      "\tLoss Det, iter 500: 0.789198100566864\n",
      "Loss Det, iter 600: 1.259316086769104\n",
      "\tLoss Det, iter 600: 0.005919686984270811\n",
      "\tLoss Det, iter 600: 0.46429815888404846\n",
      "\tLoss Det, iter 600: 0.7890982031822205\n",
      "Loss Det, iter 700: 1.2237720489501953\n",
      "\tLoss Det, iter 700: 0.005099049303680658\n",
      "\tLoss Det, iter 700: 0.42971593141555786\n",
      "\tLoss Det, iter 700: 0.7889571189880371\n",
      "Loss Det, iter 800: 1.1945027112960815\n",
      "\tLoss Det, iter 800: 0.004509539809077978\n",
      "\tLoss Det, iter 800: 0.4011140465736389\n",
      "\tLoss Det, iter 800: 0.7888790965080261\n",
      "Loss Det, iter 900: 1.1685359477996826\n",
      "\tLoss Det, iter 900: 0.004039271268993616\n",
      "\tLoss Det, iter 900: 0.375847727060318\n",
      "\tLoss Det, iter 900: 0.7886489629745483\n",
      "Loss Det, iter 1000: 1.1486313343048096\n",
      "\tLoss Det, iter 1000: 0.0036874650977551937\n",
      "\tLoss Det, iter 1000: 0.35626843571662903\n",
      "\tLoss Det, iter 1000: 0.7886753678321838\n",
      "Loss Det, iter 1100: 1.1380739212036133\n",
      "\tLoss Det, iter 1100: 0.003642830066382885\n",
      "\tLoss Det, iter 1100: 0.3458329737186432\n",
      "\tLoss Det, iter 1100: 0.7885981202125549\n",
      "Loss Det, iter 1200: 1.1352020502090454\n",
      "\tLoss Det, iter 1200: 0.0036065876483917236\n",
      "\tLoss Det, iter 1200: 0.3430130183696747\n",
      "\tLoss Det, iter 1200: 0.788582444190979\n",
      "Loss Det, iter 1300: 1.132514238357544\n",
      "\tLoss Det, iter 1300: 0.0035688383504748344\n",
      "\tLoss Det, iter 1300: 0.34037479758262634\n",
      "\tLoss Det, iter 1300: 0.7885706424713135\n",
      "Loss Det, iter 1400: 1.1299493312835693\n",
      "\tLoss Det, iter 1400: 0.00353267346508801\n",
      "\tLoss Det, iter 1400: 0.33786439895629883\n",
      "\tLoss Det, iter 1400: 0.7885522246360779\n",
      "Loss Det, iter 1500: 1.1274874210357666\n",
      "\tLoss Det, iter 1500: 0.0034954200964421034\n",
      "\tLoss Det, iter 1500: 0.3354593813419342\n",
      "\tLoss Det, iter 1500: 0.7885326147079468\n",
      "Loss Det, iter 1600: 1.127246618270874\n",
      "\tLoss Det, iter 1600: 0.0034916310105472803\n",
      "\tLoss Det, iter 1600: 0.3352237939834595\n",
      "\tLoss Det, iter 1600: 0.7885311841964722\n",
      "Loss Det, iter 1700: 1.1270055770874023\n",
      "\tLoss Det, iter 1700: 0.0034876116551458836\n",
      "\tLoss Det, iter 1700: 0.334989070892334\n",
      "\tLoss Det, iter 1700: 0.7885288596153259\n",
      "Loss Det, iter 1800: 1.1267659664154053\n",
      "\tLoss Det, iter 1800: 0.003484007902443409\n",
      "\tLoss Det, iter 1800: 0.33475443720817566\n",
      "\tLoss Det, iter 1800: 0.7885274887084961\n",
      "Loss Det, iter 1900: 1.1265300512313843\n",
      "\tLoss Det, iter 1900: 0.0034802791196852922\n",
      "\tLoss Det, iter 1900: 0.33452415466308594\n",
      "\tLoss Det, iter 1900: 0.7885255813598633\n",
      "Overfit complete\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    # Unpack config\n",
    "    root_dir = config[\"root_dir\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    num_workers = config[\"num_workers\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    learning_rate = config[\"lr\"]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset and loader\n",
    "    dataloader = get_dataset(\n",
    "        root_dir=root_dir,\n",
    "        split=\"train\",\n",
    "        transform=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = Res18FPNCEASC(config_path=config[\"config_path\"], num_classes=10)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate) \n",
    "    scheduler = StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "    \n",
    "    # Losses\n",
    "    l_det = DetectionLoss(num_bins=16, num_classes=10, num_anchors=6)\n",
    "\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    images = batch[\"image\"].to(device)\n",
    "    targets = {\n",
    "        \"boxes\": batch[\"boxes\"],\n",
    "        \"labels\": batch[\"labels\"],\n",
    "        \"image_id\": batch[\"image_id\"],\n",
    "        \"orig_size\": batch[\"orig_size\"],\n",
    "    }\n",
    "    print(\"\\nüîç Inspecting `targets` structure:\")\n",
    "    for i in range(len(targets[\"boxes\"])):\n",
    "        print(f\"--- Sample {i} ---\")\n",
    "        print(f\"Image ID:         {targets['image_id'][i]}\")\n",
    "        print(f\"Original Size:    {targets['orig_size'][i]}\")\n",
    "        print(f\"Boxes shape:      {targets['boxes'][i].shape}\")  # [N_i, 4]\n",
    "        print(f\"Labels shape:     {targets['labels'][i].shape}\")  # [N_i]\n",
    "        print(f\"Boxes:            {targets['boxes'][i]}\")\n",
    "        print(f\"Labels:           {targets['labels'][i]}\")\n",
    "\n",
    "    n_iters = 2000\n",
    "\n",
    "    # writer = SummaryWriter()\n",
    "    \n",
    "    for n in range(n_iters):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(images, stage=\"train\")\n",
    "        (\n",
    "            cls_outs,\n",
    "            reg_outs,\n",
    "            soft_mask_outs,\n",
    "            sparse_cls_feats_outs,\n",
    "            sparse_reg_feats_outs,\n",
    "            dense_cls_feats_outs,\n",
    "            dense_reg_feats_outs,\n",
    "            feats,\n",
    "            anchors,\n",
    "        ) = outputs\n",
    "\n",
    "        # print(\"\\nüîç Output shapes from model:\")\n",
    "        # for i in range(len(cls_outs)):\n",
    "        #     print(f\"--- FPN Level {i} ---\")\n",
    "        #     print(f\"cls_outs[{i}]:              {safe_shape(cls_outs[i])}\")\n",
    "        #     print(f\"reg_outs[{i}]:              {safe_shape(reg_outs[i])}\")\n",
    "        #     print(\n",
    "        #         f\"soft_mask_outs[{i}]:    {safe_shape(soft_mask_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"sparse_cls_feats[{i}]:      {safe_shape(sparse_cls_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"sparse_reg_feats[{i}]:      {safe_shape(sparse_reg_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"dense_cls_feats[{i}]:       {safe_shape(dense_cls_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"dense_reg_feats[{i}]:       {safe_shape(dense_reg_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(f\"feats[{i}]:                 {safe_shape(feats[i])}\")\n",
    "        \n",
    "        # for i, anchor in enumerate(anchors):\n",
    "        #     print(f\"P{i+3} Anchors shape: {anchor.shape}\")\n",
    "\n",
    "        loss_det = l_det(cls_outs, reg_outs, anchors, targets, device=device)\n",
    "    \n",
    "        if n % 100 == 0:\n",
    "            print(f\"Loss Det, iter {n}: {loss_det['total_loss'].item()}\")\n",
    "            print(f\"\\tLoss Det, iter {n}: {loss_det['qfl'].item()}\")\n",
    "            print(f\"\\tLoss Det, iter {n}: {loss_det['dfl'].item()}\")\n",
    "            print(f\"\\tLoss Det, iter {n}: {loss_det['giou'].item()}\")\n",
    "            \n",
    "        # writer.add_scalar('Norm Loss/overfit',loss_norm.item(),n)\n",
    "\n",
    "        loss_det[\"total_loss\"].backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # writer.close()\n",
    "    print('Overfit complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
