{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e767763-752c-4c9a-8119-4e312c5204ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook for overfitting Lnorm on one image of UAVDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d36f49-6812-49bd-bf78-573d95418b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add parent directory, it should add parent of parent\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import Res18FPNCEASC  # Adjust as needed\n",
    "from utils.uavdt_dataloader import get_dataset\n",
    "from utils.losses import Lnorm, Lamm  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a28dba7-0b10-46fa-bf73-e9b20e867bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_shape(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.shape\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        return [safe_shape(e) for e in x]\n",
    "    return type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3596626a-595d-42ab-b80f-32471030ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the setup \n",
    "mode = \"train\"  # Change to \"eval\" or \"test\" as needed\n",
    "\n",
    "config = {\n",
    "    \"root_dir\": \"/home/eyakub/scratch/CEASC_replicate\",\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 4,\n",
    "    \"num_epochs\": 1,\n",
    "    \"lr\": 1e-2,\n",
    "    \"config_path\": \"../configs/resnet18_fpn_feature_extractor.py\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c0ed48-ae61-45c5-af48-465bcaa6a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Inspecting `targets` structure:\n",
      "--- Sample 0 ---\n",
      "Image ID:         tensor([23497])\n",
      "Original Size:    tensor([ 540, 1024])\n",
      "Boxes shape:      torch.Size([17, 4])\n",
      "Labels shape:     torch.Size([17])\n",
      "Boxes:            tensor([[892., 202., 951., 222.],\n",
      "        [713., 157., 831., 196.],\n",
      "        [586., 197., 637., 216.],\n",
      "        [293., 235., 359., 258.],\n",
      "        [368., 219., 427., 242.],\n",
      "        [385., 180., 436., 199.],\n",
      "        [259., 342., 303., 396.],\n",
      "        [165., 183., 214., 204.],\n",
      "        [231., 197., 285., 220.],\n",
      "        [285., 192., 335., 211.],\n",
      "        [326., 205., 380., 227.],\n",
      "        [ 17., 236.,  84., 261.],\n",
      "        [655., 246., 716., 274.],\n",
      "        [ 75., 189., 127., 210.],\n",
      "        [851., 243., 922., 269.],\n",
      "        [591., 234., 655., 258.],\n",
      "        [901., 213., 964., 242.]])\n",
      "Labels:           tensor([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "Loss Norm, iter 0: 0.8720032572746277\n",
      "Loss Norm, iter 1: 0.8565906882286072\n",
      "Loss Norm, iter 2: 0.8577228784561157\n",
      "Loss Norm, iter 3: 0.8333345651626587\n",
      "Loss Norm, iter 4: 0.8110225796699524\n",
      "Loss Norm, iter 5: 0.8070657849311829\n",
      "Loss Norm, iter 6: 0.7882722616195679\n",
      "Loss Norm, iter 7: 0.7947258353233337\n",
      "Loss Norm, iter 8: 0.7747678756713867\n",
      "Loss Norm, iter 9: 0.7548193335533142\n",
      "Loss Norm, iter 10: 0.7549476027488708\n",
      "Loss Norm, iter 11: 0.7474735975265503\n",
      "Loss Norm, iter 12: 0.7321860194206238\n",
      "Loss Norm, iter 13: 0.7224780321121216\n",
      "Loss Norm, iter 14: 0.722259521484375\n",
      "Loss Norm, iter 15: 0.7099997997283936\n",
      "Loss Norm, iter 16: 0.7021925449371338\n",
      "Loss Norm, iter 17: 0.6956409811973572\n",
      "Loss Norm, iter 18: 0.6931836605072021\n",
      "Loss Norm, iter 19: 0.6893853545188904\n",
      "Loss Norm, iter 20: 0.6844784617424011\n",
      "Loss Norm, iter 21: 0.6731853485107422\n",
      "Loss Norm, iter 22: 0.6640547513961792\n",
      "Loss Norm, iter 23: 0.6696650385856628\n",
      "Loss Norm, iter 24: 0.6560946702957153\n",
      "Loss Norm, iter 25: 0.6521474123001099\n",
      "Loss Norm, iter 26: 0.6390659809112549\n",
      "Loss Norm, iter 27: 0.6384248733520508\n",
      "Loss Norm, iter 28: 0.6283079981803894\n",
      "Loss Norm, iter 29: 0.6224119067192078\n",
      "Loss Norm, iter 30: 0.6199437975883484\n",
      "Loss Norm, iter 31: 0.6114165186882019\n",
      "Loss Norm, iter 32: 0.6079756617546082\n",
      "Loss Norm, iter 33: 0.5958094000816345\n",
      "Loss Norm, iter 34: 0.5934218764305115\n",
      "Loss Norm, iter 35: 0.5939728617668152\n",
      "Loss Norm, iter 36: 0.5852488875389099\n",
      "Loss Norm, iter 37: 0.5800843238830566\n",
      "Loss Norm, iter 38: 0.5606834292411804\n",
      "Loss Norm, iter 39: 0.5707603693008423\n",
      "Loss Norm, iter 40: 0.5627745389938354\n",
      "Loss Norm, iter 41: 0.5725395679473877\n",
      "Loss Norm, iter 42: 0.5540586113929749\n",
      "Loss Norm, iter 43: 0.5519322752952576\n",
      "Loss Norm, iter 44: 0.5376356244087219\n",
      "Loss Norm, iter 45: 0.5367048382759094\n",
      "Loss Norm, iter 46: 0.5181857943534851\n",
      "Loss Norm, iter 47: 0.5316435098648071\n",
      "Loss Norm, iter 48: 0.5163851976394653\n",
      "Loss Norm, iter 49: 0.5126500129699707\n",
      "Loss Norm, iter 50: 0.4970167279243469\n",
      "Loss Norm, iter 51: 0.4892800748348236\n",
      "Loss Norm, iter 52: 0.4974963366985321\n",
      "Loss Norm, iter 53: 0.49659180641174316\n",
      "Loss Norm, iter 54: 0.4851875901222229\n",
      "Loss Norm, iter 55: 0.4722919166088104\n",
      "Loss Norm, iter 56: 0.4703480899333954\n",
      "Loss Norm, iter 57: 0.4681926369667053\n",
      "Loss Norm, iter 58: 0.4747062623500824\n",
      "Loss Norm, iter 59: 0.45941779017448425\n",
      "Loss Norm, iter 60: 0.44527289271354675\n",
      "Loss Norm, iter 61: 0.45755887031555176\n",
      "Loss Norm, iter 62: 0.4585542678833008\n",
      "Loss Norm, iter 63: 0.42822346091270447\n",
      "Loss Norm, iter 64: 0.4298357665538788\n",
      "Loss Norm, iter 65: 0.42044469714164734\n",
      "Loss Norm, iter 66: 0.4167104661464691\n",
      "Loss Norm, iter 67: 0.42467784881591797\n",
      "Loss Norm, iter 68: 0.39931991696357727\n",
      "Loss Norm, iter 69: 0.39319267868995667\n",
      "Loss Norm, iter 70: 0.38244765996932983\n",
      "Loss Norm, iter 71: 0.435059517621994\n",
      "Loss Norm, iter 72: 0.40224432945251465\n",
      "Loss Norm, iter 73: 0.40289759635925293\n",
      "Loss Norm, iter 74: 0.370682030916214\n",
      "Loss Norm, iter 75: 0.4411349296569824\n",
      "Loss Norm, iter 76: 0.3870447278022766\n",
      "Loss Norm, iter 77: 0.41400012373924255\n",
      "Loss Norm, iter 78: 0.3587983548641205\n",
      "Loss Norm, iter 79: 0.34923264384269714\n",
      "Loss Norm, iter 80: 0.41415128111839294\n",
      "Loss Norm, iter 81: 0.3836127817630768\n",
      "Loss Norm, iter 82: 0.3533426523208618\n",
      "Loss Norm, iter 83: 0.3361518085002899\n",
      "Loss Norm, iter 84: 0.34566447138786316\n",
      "Loss Norm, iter 85: 0.3545108735561371\n",
      "Loss Norm, iter 86: 0.3224336504936218\n",
      "Loss Norm, iter 87: 0.32868537306785583\n",
      "Loss Norm, iter 88: 0.3255802094936371\n",
      "Loss Norm, iter 89: 0.34423884749412537\n",
      "Loss Norm, iter 90: 0.3443082273006439\n",
      "Loss Norm, iter 91: 0.2977820336818695\n",
      "Loss Norm, iter 92: 0.3147991895675659\n",
      "Loss Norm, iter 93: 0.3549976348876953\n",
      "Loss Norm, iter 94: 0.29362615942955017\n",
      "Loss Norm, iter 95: 0.3230530917644501\n",
      "Loss Norm, iter 96: 0.2914861738681793\n",
      "Loss Norm, iter 97: 0.3607015311717987\n",
      "Loss Norm, iter 98: 0.3263081908226013\n",
      "Loss Norm, iter 99: 0.28803133964538574\n",
      "Overfit complete\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Unpack config\n",
    "    root_dir = config[\"root_dir\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    num_workers = config[\"num_workers\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    learning_rate = config[\"lr\"]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset and loader\n",
    "    dataloader = get_dataset(\n",
    "        root_dir=root_dir,\n",
    "        split=\"train\",\n",
    "        transform=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = Res18FPNCEASC(config_path=config[\"config_path\"], num_classes=3)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "    \n",
    "    # Losses\n",
    "    l_norm = Lnorm()\n",
    "\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    images = batch[\"image\"].to(device)\n",
    "    targets = {\n",
    "        \"boxes\": batch[\"boxes\"],\n",
    "        \"labels\": batch[\"labels\"],\n",
    "        \"image_id\": batch[\"image_id\"],\n",
    "        \"orig_size\": batch[\"orig_size\"],\n",
    "    }\n",
    "    print(\"\\nüîç Inspecting `targets` structure:\")\n",
    "    for i in range(len(targets[\"boxes\"])):\n",
    "        print(f\"--- Sample {i} ---\")\n",
    "        print(f\"Image ID:         {targets['image_id'][i]}\")\n",
    "        print(f\"Original Size:    {targets['orig_size'][i]}\")\n",
    "        print(f\"Boxes shape:      {targets['boxes'][i].shape}\")  # [N_i, 4]\n",
    "        print(f\"Labels shape:     {targets['labels'][i].shape}\")  # [N_i]\n",
    "        print(f\"Boxes:            {targets['boxes'][i]}\")\n",
    "        print(f\"Labels:           {targets['labels'][i]}\")\n",
    "\n",
    "    n_iters = 100\n",
    "\n",
    "    # writer = SummaryWriter()\n",
    "    \n",
    "    for n in range(n_iters):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(images, stage=\"train\")\n",
    "        (\n",
    "            cls_outs,\n",
    "            reg_outs,\n",
    "            soft_mask_outs,\n",
    "            sparse_cls_feats_outs,\n",
    "            sparse_reg_feats_outs,\n",
    "            dense_cls_feats_outs,\n",
    "            dense_reg_feats_outs,\n",
    "            feats,\n",
    "            anchors,\n",
    "        ) = outputs\n",
    "\n",
    "        # print(\"\\nüîç Output shapes from model:\")\n",
    "        # for i in range(len(cls_outs)):\n",
    "        #     print(f\"--- FPN Level {i} ---\")\n",
    "        #     print(f\"cls_outs[{i}]:              {safe_shape(cls_outs[i])}\")\n",
    "        #     print(f\"reg_outs[{i}]:              {safe_shape(reg_outs[i])}\")\n",
    "        #     print(\n",
    "        #         f\"soft_mask_outs[{i}]:    {safe_shape(soft_mask_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"sparse_cls_feats[{i}]:      {safe_shape(sparse_cls_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"sparse_reg_feats[{i}]:      {safe_shape(sparse_reg_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"dense_cls_feats[{i}]:       {safe_shape(dense_cls_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"dense_reg_feats[{i}]:       {safe_shape(dense_reg_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(f\"feats[{i}]:                 {safe_shape(feats[i])}\")\n",
    "        \n",
    "        # for i, anchor in enumerate(anchors):\n",
    "        #     print(f\"P{i+3} Anchors shape: {anchor.shape}\")\n",
    "\n",
    "        loss_norm = l_norm(\n",
    "                sparse_cls_feats_outs, soft_mask_outs, dense_cls_feats_outs\n",
    "            )\n",
    "    \n",
    "        print(f\"Loss Norm, iter {n}: {loss_norm.item()}\")\n",
    "\n",
    "        # writer.add_scalar('Norm Loss/overfit',loss_norm.item(),n)\n",
    "\n",
    "        loss_norm.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "\n",
    "    # writer.close()\n",
    "    print('Overfit complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15553460-9e37-4c1f-955e-a084e19defde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
