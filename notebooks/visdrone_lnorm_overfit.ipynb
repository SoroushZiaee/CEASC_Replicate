{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fa3fd-29d1-4f75-8e36-c7100b1959e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook for overfitting Lnorm on one image of UAVDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e70a5d6-e731-405b-bfe5-fba0968f0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add parent directory, it should add parent of parent\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import Res18FPNCEASC  # Adjust as needed\n",
    "from utils.visdrone_dataloader import get_dataset\n",
    "from utils.losses import Lnorm, Lamm  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73024509-5640-4aae-b8c2-bb2292bb249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_shape(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.shape\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        return [safe_shape(e) for e in x]\n",
    "    return type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc98f2c-0835-41be-9bb1-5e57d9e5fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# get the setup \n",
    "mode = \"train\"  # Change to \"eval\" or \"test\" as needed\n",
    "\n",
    "config = {\n",
    "    \"root_dir\": \"/home/soroush1/scratch/eecs_project\",\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 4,\n",
    "    \"num_epochs\": 1,\n",
    "    \"lr\": 1e-1,\n",
    "    \"config_path\": \"../configs/resnet18_fpn_feature_extractor.py\",\n",
    "}\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868a5894-f75c-427d-b1d6-d10125bab770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Inspecting `targets` structure:\n",
      "--- Sample 0 ---\n",
      "Image ID:         tensor([6254])\n",
      "Original Size:    tensor([1500, 2000])\n",
      "Boxes shape:      torch.Size([56, 4])\n",
      "Labels shape:     torch.Size([56])\n",
      "Boxes:            tensor([[   0., 1354.,   97., 1423.],\n",
      "        [ 248., 1184.,  403., 1289.],\n",
      "        [ 399., 1093.,  511., 1200.],\n",
      "        [ 396., 1089.,  523., 1213.],\n",
      "        [ 107.,  911.,  220., 1016.],\n",
      "        [ 544., 1080.,  653., 1196.],\n",
      "        [ 620., 1075.,  737., 1180.],\n",
      "        [ 312., 1229.,  845., 1500.],\n",
      "        [1294., 1286., 1398., 1419.],\n",
      "        [1281., 1277., 1418., 1437.],\n",
      "        [1103., 1124., 1173., 1214.],\n",
      "        [1315., 1051., 1385., 1137.],\n",
      "        [1207., 1023., 1270., 1137.],\n",
      "        [1141., 1028., 1202., 1101.],\n",
      "        [1217.,  932., 1287., 1032.],\n",
      "        [1289.,  908., 1359.,  996.],\n",
      "        [1303.,  793., 1360.,  910.],\n",
      "        [1372.,  700., 1434.,  789.],\n",
      "        [1387.,  750., 1448.,  882.],\n",
      "        [1214.,  770., 1259.,  864.],\n",
      "        [1179.,  782., 1224.,  876.],\n",
      "        [1086.,  776., 1149.,  869.],\n",
      "        [1064.,  759., 1165.,  883.],\n",
      "        [1191.,  709., 1252.,  800.],\n",
      "        [1244.,  698., 1282.,  791.],\n",
      "        [1297.,  631., 1354.,  739.],\n",
      "        [1313.,  592., 1369.,  684.],\n",
      "        [1237.,  464., 1297.,  562.],\n",
      "        [1321.,  467., 1376.,  570.],\n",
      "        [1377.,  464., 1418.,  529.],\n",
      "        [1364.,  406., 1407.,  501.],\n",
      "        [1473.,  320., 1578.,  387.],\n",
      "        [1355.,  237., 1446.,  308.],\n",
      "        [1250.,  255., 1286.,  334.],\n",
      "        [1280.,  302., 1313.,  387.],\n",
      "        [1269.,  246., 1321.,  331.],\n",
      "        [ 953.,  269., 1246.,  392.],\n",
      "        [ 901.,  396.,  960.,  504.],\n",
      "        [1004.,  212., 1217.,  310.],\n",
      "        [1074.,  154., 1256.,  274.],\n",
      "        [1087.,   68., 1270.,  184.],\n",
      "        [1013.,   16., 1051.,   87.],\n",
      "        [ 637.,  537.,  811.,  764.],\n",
      "        [ 342.,  513.,  684.,  682.],\n",
      "        [ 273.,  427.,  558.,  543.],\n",
      "        [ 489.,  260.,  772.,  398.],\n",
      "        [ 780.,  207.,  837.,  273.],\n",
      "        [ 734.,   74.,  903.,  188.],\n",
      "        [ 727.,   32.,  902.,  120.],\n",
      "        [ 881.,    0.,  905.,   41.],\n",
      "        [1318.,  129., 1421.,  259.],\n",
      "        [ 356.,  133.,  407.,  214.],\n",
      "        [ 313.,  137.,  367.,  191.],\n",
      "        [ 285.,  148.,  326.,  198.],\n",
      "        [ 185.,  201.,  246.,  262.],\n",
      "        [1420.,  622., 1463.,  732.]])\n",
      "Labels:           tensor([ 1,  1,  2, 10,  1,  2,  2,  4,  2, 10,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         3,  1,  1,  2, 10,  1,  1,  1,  1, 10,  1,  1,  1, 10, 10,  1,  1,  1,\n",
      "         4, 10,  5,  5,  5,  1,  5,  5,  5,  5, 10,  5,  5,  1,  5,  1,  2,  2,\n",
      "         3,  1])\n",
      "Loss Norm, iter 0: 0.8716927766799927\n",
      "Loss Norm, iter 100: 0.14222507178783417\n",
      "Loss Norm, iter 200: 0.12590083479881287\n",
      "Loss Norm, iter 300: 0.12124516814947128\n",
      "Loss Norm, iter 400: 0.11865957826375961\n",
      "Loss Norm, iter 500: 0.11654720455408096\n",
      "Loss Norm, iter 600: 0.11633401364088058\n",
      "Loss Norm, iter 700: 0.11611805111169815\n",
      "Loss Norm, iter 800: 0.1158987507224083\n",
      "Loss Norm, iter 900: 0.11567556858062744\n",
      "Loss Norm, iter 1000: 0.11544828861951828\n",
      "Loss Norm, iter 1100: 0.11542512476444244\n",
      "Loss Norm, iter 1200: 0.11540196090936661\n",
      "Loss Norm, iter 1300: 0.11537875980138779\n",
      "Loss Norm, iter 1400: 0.11535556614398956\n",
      "Loss Norm, iter 1500: 0.11533226072788239\n",
      "Loss Norm, iter 1600: 0.11533041298389435\n",
      "Loss Norm, iter 1700: 0.11532849073410034\n",
      "Loss Norm, iter 1800: 0.11532659828662872\n",
      "Loss Norm, iter 1900: 0.1153247132897377\n",
      "Overfit complete\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Unpack config\n",
    "    root_dir = config[\"root_dir\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    num_workers = config[\"num_workers\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    learning_rate = config[\"lr\"]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset and loader\n",
    "    dataloader = get_dataset(\n",
    "        root_dir=root_dir,\n",
    "        split=\"train\",\n",
    "        transform=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = Res18FPNCEASC(config_path=config[\"config_path\"], num_classes=10)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True) \n",
    "    scheduler = StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "    \n",
    "    # Losses\n",
    "    l_norm = Lnorm()\n",
    "\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    images = batch[\"image\"].to(device)\n",
    "    targets = {\n",
    "        \"boxes\": batch[\"boxes\"],\n",
    "        \"labels\": batch[\"labels\"],\n",
    "        \"image_id\": batch[\"image_id\"],\n",
    "        \"orig_size\": batch[\"orig_size\"],\n",
    "    }\n",
    "    print(\"\\nüîç Inspecting `targets` structure:\")\n",
    "    for i in range(len(targets[\"boxes\"])):\n",
    "        print(f\"--- Sample {i} ---\")\n",
    "        print(f\"Image ID:         {targets['image_id'][i]}\")\n",
    "        print(f\"Original Size:    {targets['orig_size'][i]}\")\n",
    "        print(f\"Boxes shape:      {targets['boxes'][i].shape}\")  # [N_i, 4]\n",
    "        print(f\"Labels shape:     {targets['labels'][i].shape}\")  # [N_i]\n",
    "        print(f\"Boxes:            {targets['boxes'][i]}\")\n",
    "        print(f\"Labels:           {targets['labels'][i]}\")\n",
    "\n",
    "    n_iters = 2000\n",
    "\n",
    "    # writer = SummaryWriter()\n",
    "    \n",
    "    for n in range(n_iters):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(images, stage=\"train\")\n",
    "        (\n",
    "            cls_outs,\n",
    "            reg_outs,\n",
    "            soft_mask_outs,\n",
    "            sparse_cls_feats_outs,\n",
    "            sparse_reg_feats_outs,\n",
    "            dense_cls_feats_outs,\n",
    "            dense_reg_feats_outs,\n",
    "            feats,\n",
    "            anchors,\n",
    "        ) = outputs\n",
    "\n",
    "        # print(\"\\nüîç Output shapes from model:\")\n",
    "        # for i in range(len(cls_outs)):\n",
    "        #     print(f\"--- FPN Level {i} ---\")\n",
    "        #     print(f\"cls_outs[{i}]:              {safe_shape(cls_outs[i])}\")\n",
    "        #     print(f\"reg_outs[{i}]:              {safe_shape(reg_outs[i])}\")\n",
    "        #     print(\n",
    "        #         f\"soft_mask_outs[{i}]:    {safe_shape(soft_mask_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"sparse_cls_feats[{i}]:      {safe_shape(sparse_cls_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"sparse_reg_feats[{i}]:      {safe_shape(sparse_reg_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"dense_cls_feats[{i}]:       {safe_shape(dense_cls_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(\n",
    "        #         f\"dense_reg_feats[{i}]:       {safe_shape(dense_reg_feats_outs[i])}\"\n",
    "        #     )\n",
    "        #     print(f\"feats[{i}]:                 {safe_shape(feats[i])}\")\n",
    "        \n",
    "        # for i, anchor in enumerate(anchors):\n",
    "        #     print(f\"P{i+3} Anchors shape: {anchor.shape}\")\n",
    "\n",
    "        loss_norm = l_norm(\n",
    "                sparse_cls_feats_outs, soft_mask_outs, dense_cls_feats_outs\n",
    "            )\n",
    "    \n",
    "        if n % 100 == 0:\n",
    "            print(f\"Loss Norm, iter {n}: {loss_norm.item()}\")\n",
    "\n",
    "        # writer.add_scalar('Norm Loss/overfit',loss_norm.item(),n)\n",
    "\n",
    "        loss_norm.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # writer.close()\n",
    "    print('Overfit complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6575b7a-ed88-4c7e-be23-1f3d5fd3e127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
