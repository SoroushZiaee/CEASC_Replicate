{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9dbeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add parent directory, it should add parent of parent\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import Res18FPNCEASC  # Adjust as needed\n",
    "from utils.uavdt_dataloader import get_dataset\n",
    "from utils.losses import Lnorm, Lamm  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c3fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_shape(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.shape\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        return [safe_shape(e) for e in x]\n",
    "    return type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86e0e8e2-694a-48bd-859f-fefd265c34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the setup \n",
    "mode = \"train\"  # Change to \"eval\" or \"test\" as needed\n",
    "\n",
    "config = {\n",
    "    \"root_dir\": \"/home/eyakub/scratch/CEASC_replicate\",\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 4,\n",
    "    \"num_epochs\": 1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"config_path\": \"../configs/resnet18_fpn_feature_extractor.py\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32db26d4-5c8c-49e9-99af-f94b739246c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lustre06/project/6067616/eyakub/CEASC_Replicate/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b53af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# Unpack config\n",
    "root_dir = config[\"root_dir\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "num_workers = config[\"num_workers\"]\n",
    "num_epochs = config[\"num_epochs\"]\n",
    "learning_rate = config[\"lr\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset and loader\n",
    "dataloader = get_dataset(\n",
    "    root_dir=root_dir,\n",
    "    split=\"train\",\n",
    "    transform=None,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = Res18FPNCEASC(config_path=config[\"config_path\"], num_classes=3)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # NOTE: Adam was not used in the paper\n",
    "\n",
    "# Losses\n",
    "# l_norm = Lnorm() # there is some dimensions error that needs to be fixed\n",
    "l_amm = Lamm()\n",
    "print(\"Lamm base classes:\", Lamm.__bases__)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "images = batch[\"image\"].to(device)\n",
    "targets = {\n",
    "    \"boxes\": batch[\"boxes\"],\n",
    "    \"labels\": batch[\"labels\"],\n",
    "    \"image_id\": batch[\"image_id\"],\n",
    "    \"orig_size\": batch[\"orig_size\"],\n",
    "}\n",
    "print(\"\\nüîç Inspecting `targets` structure:\")\n",
    "for i in range(len(targets[\"boxes\"])):\n",
    "    print(f\"--- Sample {i} ---\")\n",
    "    print(f\"Image ID:         {targets['image_id'][i]}\")\n",
    "    print(f\"Original Size:    {targets['orig_size'][i]}\")\n",
    "    print(f\"Boxes shape:      {targets['boxes'][i].shape}\")  # [N_i, 4]\n",
    "    print(f\"Labels shape:     {targets['labels'][i].shape}\")  # [N_i]\n",
    "    print(f\"Boxes:            {targets['boxes'][i]}\")\n",
    "    print(f\"Labels:           {targets['labels'][i]}\")\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(images, stage=\"train\")\n",
    "(\n",
    "    cls_outs,\n",
    "    reg_outs,\n",
    "    cls_soft_mask_outs,\n",
    "    reg_soft_mask_outs,\n",
    "    sparse_cls_feats_outs,\n",
    "    sparse_reg_feats_outs,\n",
    "    dense_cls_feats_outs,\n",
    "    dense_reg_feats_outs,\n",
    "    feats,\n",
    "    anchors,\n",
    ") = outputs\n",
    "\n",
    "print(\"\\nüîç Output shapes from model:\")\n",
    "for i in range(len(cls_outs)):\n",
    "    print(f\"--- FPN Level {i} ---\")\n",
    "    print(f\"cls_outs[{i}]:              {safe_shape(cls_outs[i])}\")\n",
    "    print(f\"reg_outs[{i}]:              {safe_shape(reg_outs[i])}\")\n",
    "    print(\n",
    "        f\"cls_soft_mask_outs[{i}]:    {safe_shape(cls_soft_mask_outs[i])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"reg_soft_mask_outs[{i}]:    {safe_shape(reg_soft_mask_outs[i])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"sparse_cls_feats[{i}]:      {safe_shape(sparse_cls_feats_outs[i])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"sparse_reg_feats[{i}]:      {safe_shape(sparse_reg_feats_outs[i])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"dense_cls_feats[{i}]:       {safe_shape(dense_cls_feats_outs[i])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"dense_reg_feats[{i}]:       {safe_shape(dense_reg_feats_outs[i])}\"\n",
    "    )\n",
    "    print(f\"feats[{i}]:                 {safe_shape(feats[i])}\")\n",
    "\n",
    "for i, anchor in enumerate(anchors):\n",
    "    print(f\"P{i+3} Anchors shape: {anchor.shape}\")\n",
    "\n",
    "# loss_norm = l_norm(\n",
    "#     sparse_cls_feats_outs, cls_soft_mask_outs, dense_cls_feats_outs\n",
    "# )\n",
    "\n",
    "print(\"l_amm type:\", type(l_amm))\n",
    "print(\"isinstance l_amm of nn.Module:\", isinstance(l_amm, torch.nn.Module))\n",
    "print(\"dir(l_amm):\", dir(l_amm))\n",
    "\n",
    "loss_amm = l_amm(\n",
    "    reg_soft_mask_outs, targets[\"boxes\"], im_dimx=1024, im_dimy=540\n",
    ")  # used the soft masks in this version, might be incorrect\n",
    "\n",
    "# print(f\"Loss Norm: {loss_norm.item()}\")\n",
    "print(f\"Loss AMM: {loss_amm.item()}\")\n",
    "\n",
    "# Calculate loss ‚Äî you must define this to fit CEASC\n",
    "# loss = ceasc_loss(outputs, targets)  # Custom function required\n",
    "# loss = 0.0\n",
    "# # make the loss a torch tensor\n",
    "# loss = torch.tensor(loss, dtype=torch.float32).to(device)\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "# # loss.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "# # total_loss += loss.item()\n",
    "# progress_bar.set_postfix(loss=loss.item())\n",
    "# break\n",
    "\n",
    "# print(f\"Epoch {epoch + 1}: Total Loss = {total_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "# torch.save(model.state_dict(), \"weights/ceasc_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a6b0c-8ad3-4047-9568-5f412631201a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
